from cassandra.cluster import Cluster
from datasets import (
    load_dataset,
)
from jet.adapters.langchain.chat_ollama import ChatOllama, OllamaEmbeddings
from jet.logger import logger
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Cassandra
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_text_splitters import RecursiveCharacterTextSplitter
import cassio
import os
import shutil


OUTPUT_DIR = os.path.join(
    os.path.dirname(__file__), "generated", os.path.splitext(os.path.basename(__file__))[0])
shutil.rmtree(OUTPUT_DIR, ignore_errors=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
log_file = os.path.join(OUTPUT_DIR, "main.log")
logger.basicConfig(filename=log_file)
logger.info(f"Logs: {log_file}")

PERSIST_DIR = f"{OUTPUT_DIR}/chroma"
os.makedirs(PERSIST_DIR, exist_ok=True)

"""
# Apache Cassandra

This page provides a quickstart for using [Apache CassandraÂ®](https://cassandra.apache.org/) as a Vector Store.

> [Cassandra](https://cassandra.apache.org/) is a NoSQL, row-oriented, highly scalable and highly available database.Starting with version 5.0, the database ships with [vector search capabilities](https://cassandra.apache.org/doc/trunk/cassandra/vector-search/overview.html).

_Note: in addition to access to the database, an Ollama API Key is required to run the full example._

### Setup and general dependencies

Use of the integration requires the following Python package.
"""
logger.info("# Apache Cassandra")

# %pip install --upgrade --quiet langchain-community "cassio>=0.1.4"

"""
_Note: depending on your LangChain setup, you may need to install/upgrade other dependencies needed for this demo_
_(specifically, recent versions of `datasets`, `ollama`, `pypdf` and `tiktoken` are required, along with `langchain-community`)._
"""

# from getpass import getpass


# if "OPENAI_API_KEY" not in os.environ:
#     os.environ["OPENAI_API_KEY"] = getpass("OPENAI_API_KEY = ")

embe = OllamaEmbeddings(model="nomic-embed-text")

"""
## Import the Vector Store
"""
logger.info("## Import the Vector Store")


"""
## Connection parameters

The Vector Store integration shown in this page can be used with Cassandra as well as other derived databases, such as Astra DB, which use the CQL (Cassandra Query Language) protocol.

> DataStax [Astra DB](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html) is a managed serverless database built on Cassandra, offering the same interface and strengths.

Depending on whether you connect to a Cassandra cluster or to Astra DB through CQL, you will provide different parameters when creating the vector store object.

### Connecting to a Cassandra cluster

You first need to create a `cassandra.cluster.Session` object, as described in the [Cassandra driver documentation](https://docs.datastax.com/en/developer/python-driver/latest/api/cassandra/cluster/#module-cassandra.cluster). The details vary (e.g. with network settings and authentication), but this might be something like:
"""
logger.info("## Connection parameters")


cluster = Cluster(["127.0.0.1"])
session = cluster.connect()

"""
You can now set the session, along with your desired keyspace name, as a global CassIO parameter:
"""
logger.info(
    "You can now set the session, along with your desired keyspace name, as a global CassIO parameter:")


CASSANDRA_KEYSPACE = input("CASSANDRA_KEYSPACE = ")

cassio.init(session=session, keyspace=CASSANDRA_KEYSPACE)

"""
Now you can create the vector store:
"""
logger.info("Now you can create the vector store:")

vstore = Cassandra(
    embedding=embe,
    table_name="cassandra_vector_demo",
)

"""
_Note: you can also pass your session and keyspace directly as parameters when creating the vector store. Using the global `cassio.init` setting, however, comes handy if your applications uses Cassandra in several ways (for instance, for vector store, chat memory and LLM response caching), as it allows to centralize credential and DB connection management in one place._

### Connecting to Astra DB through CQL

In this case you initialize CassIO with the following connection parameters:

- the Database ID, e.g. `01234567-89ab-cdef-0123-456789abcdef`
- the Token, e.g. `AstraCS:6gBhNmsk135....` (it must be a "Database Administrator" token)
- Optionally a Keyspace name (if omitted, the default one for the database will be used)
"""
logger.info("### Connecting to Astra DB through CQL")

ASTRA_DB_ID = input("ASTRA_DB_ID = ")
# ASTRA_DB_APPLICATION_TOKEN = getpass("ASTRA_DB_APPLICATION_TOKEN = ")

desired_keyspace = input("ASTRA_DB_KEYSPACE (optional, can be left empty) = ")
if desired_keyspace:
    ASTRA_DB_KEYSPACE = desired_keyspace
else:
    ASTRA_DB_KEYSPACE = None


cassio.init(
    database_id=ASTRA_DB_ID,
    token=ASTRA_DB_APPLICATION_TOKEN,
    keyspace=ASTRA_DB_KEYSPACE,
)

"""
Now you can create the vector store:
"""
logger.info("Now you can create the vector store:")

vstore = Cassandra(
    embedding=embe,
    table_name="cassandra_vector_demo",
)

"""
## Load a dataset

Convert each entry in the source dataset into a `Document`, then write them into the vector store:
"""
logger.info("## Load a dataset")

philo_dataset = load_dataset("datastax/philosopher-quotes")["train"]

docs = []
for entry in philo_dataset:
    metadata = {"author": entry["author"]}
    doc = Document(page_content=entry["quote"], metadata=metadata)
    docs.append(doc)

inserted_ids = vstore.add_documents(docs)
logger.debug(f"\nInserted {len(inserted_ids)} documents.")

"""
In the above, `metadata` dictionaries are created from the source data and are part of the `Document`.

Add some more entries, this time with `add_texts`:
"""
logger.info("In the above, `metadata` dictionaries are created from the source data and are part of the `Document`.")

texts = ["I think, therefore I am.", "To the things themselves!"]
metadatas = [{"author": "descartes"}, {"author": "husserl"}]
ids = ["desc_01", "huss_xy"]

inserted_ids_2 = vstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)
logger.debug(f"\nInserted {len(inserted_ids_2)} documents.")

"""
_Note: you may want to speed up the execution of `add_texts` and `add_documents` by increasing the concurrency level for_
_these bulk operations - check out the methods' `batch_size` parameter_
_for more details. Depending on the network and the client machine specifications, your best-performing choice of parameters may vary._

## Run searches

This section demonstrates metadata filtering and getting the similarity scores back:
"""
logger.info("## Run searches")

results = vstore.similarity_search("Our life is what we make of it", k=3)
for res in results:
    logger.debug(f"* {res.page_content} [{res.metadata}]")

results_filtered = vstore.similarity_search(
    "Our life is what we make of it",
    k=3,
    filter={"author": "plato"},
)
for res in results_filtered:
    logger.debug(f"* {res.page_content} [{res.metadata}]")

results = vstore.similarity_search_with_score(
    "Our life is what we make of it", k=3)
for res, score in results:
    logger.debug(f"* [SIM={score:3f}] {res.page_content} [{res.metadata}]")

"""
### MMR (Maximal-marginal-relevance) search
"""
logger.info("### MMR (Maximal-marginal-relevance) search")

results = vstore.max_marginal_relevance_search(
    "Our life is what we make of it",
    k=3,
    filter={"author": "aristotle"},
)
for res in results:
    logger.debug(f"* {res.page_content} [{res.metadata}]")

"""
## Deleting stored documents
"""
logger.info("## Deleting stored documents")

delete_1 = vstore.delete(inserted_ids[:3])
logger.debug(f"all_succeed={delete_1}")  # True, all documents deleted

delete_2 = vstore.delete(inserted_ids[2:5])
# True, though some IDs were gone already
logger.debug(f"some_succeeds={delete_2}")

"""
## A minimal RAG chain

The next cells will implement a simple RAG pipeline:
- download a sample PDF file and load it onto the store;
- create a RAG chain with LCEL (LangChain Expression Language), with the vector store at its heart;
- run the question-answering chain.
"""
logger.info("## A minimal RAG chain")

# !curl -L \
"https://github.com/awesome-astra/datasets/blob/main/demo-resources/what-is-philosophy/what-is-philosophy.pdf?raw=true" \
    - o "what-is-philosophy.pdf"

pdf_loader = PyPDFLoader("what-is-philosophy.pdf")
splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)
docs_from_pdf = pdf_loader.load_and_split(text_splitter=splitter)

logger.debug(f"Documents from PDF: {len(docs_from_pdf)}.")
inserted_ids_from_pdf = vstore.add_documents(docs_from_pdf)
logger.debug(f"Inserted {len(inserted_ids_from_pdf)} documents.")

retriever = vstore.as_retriever(search_kwargs={"k": 3})

philo_template = """
You are a philosopher that draws inspiration from great thinkers of the past
to craft well-thought answers to user questions. Use the provided context as the basis
for your answers and do not make up new reasoning paths - just mix-and-match what you are given.
Your answers must be concise and to the point, and refrain from answering about other topics than philosophy.

CONTEXT:
{context}

QUESTION: {question}

YOUR ANSWER:"""

philo_prompt = ChatPromptTemplate.from_template(philo_template)

llm = ChatOllama(model="llama3.2")

chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | philo_prompt
    | llm
    | StrOutputParser()
)

chain.invoke(
    "How does Russel elaborate on Peirce's idea of the security blanket?")

"""
For more, check out a complete RAG template using Astra DB through CQL [here](https://github.com/langchain-ai/langchain/tree/master/templates/cassandra-entomology-rag).

## Cleanup

the following essentially retrieves the `Session` object from CassIO and runs a CQL `DROP TABLE` statement with it:

_(You will lose the data you stored in it.)_
"""
logger.info("## Cleanup")

cassio.config.resolve_session().execute(
    f"DROP TABLE {cassio.config.resolve_keyspace()}.cassandra_vector_demo;"
)

"""
### Learn more

For more information, extended quickstarts and additional usage examples, please visit the [CassIO documentation](https://cassio.org/frameworks/langchain/about/) for more on using the LangChain `Cassandra` vector store.

#### Attribution statement

> Apache Cassandra, Cassandra and Apache are either registered trademarks or trademarks of the [Apache Software Foundation](http://www.apache.org/) in the United States and/or other countries.
"""
logger.info("### Learn more")

logger.info("\n\n[DONE]", bright=True)
